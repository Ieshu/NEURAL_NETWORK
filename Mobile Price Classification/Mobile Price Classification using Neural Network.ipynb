{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "5           1859     0          0.5         1   3       0          22    0.7   \n",
       "6           1821     0          1.7         0   4       1          10    0.8   \n",
       "7           1954     0          0.5         1   0       0          24    0.8   \n",
       "8           1445     1          0.5         0   0       0          53    0.7   \n",
       "9            509     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#dataset import\n",
    "dataset = pd.read_csv(r'C:\\Users\\A K SHARMA\\Downloads\\11167_15520_bundle_archive\\train.csv') #You need to change #directory accordingly\n",
    "dataset.head(10) #Return 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[:,:20].values\n",
    "y = dataset.iloc[:,20:21].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90259726 -0.9900495   0.83077942 ... -1.78686097 -1.00601811\n",
      "   0.98609664]\n",
      " [-0.49513857  1.0100505  -1.2530642  ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " [-1.5376865   1.0100505  -1.2530642  ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " ...\n",
      " [ 1.53077336 -0.9900495  -0.76274805 ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " [ 0.62252745 -0.9900495  -0.76274805 ...  0.55964063  0.99401789\n",
      "   0.98609664]\n",
      " [-1.65833069  1.0100505   0.58562134 ...  0.55964063  0.99401789\n",
      "   0.98609664]]\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n",
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# y = to_categorical(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_TEST_SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING NEURAL NETWORK\n",
    "\n",
    "# 1. Building model\n",
    "\n",
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Specify loss function and optimizer\n",
    "\n",
    "''' model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "This is Sparse cross entropy,which  is used when your output is an integer like 0,1,2,3,..13. But your output is onehot encoded\n",
    "[0,0,...1,0].\n",
    "\n",
    "So use categorical cross entropy.\n",
    "\n",
    "'''\n",
    "# CATEOGORICAL CROSS ENTROPY\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\A K SHARMA\\Videos\\PYTHON\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 1.5254 - accuracy: 0.2089\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 1.4033 - accuracy: 0.2606\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 1.3242 - accuracy: 0.3244\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 1.2593 - accuracy: 0.3944\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 1.1963 - accuracy: 0.4522\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 1.1338 - accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 1.0688 - accuracy: 0.5467\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 1.0047 - accuracy: 0.5811\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.9393 - accuracy: 0.6083\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.8770 - accuracy: 0.6367\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.8171 - accuracy: 0.6600\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.7614 - accuracy: 0.6828\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.7095 - accuracy: 0.7078\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.6625 - accuracy: 0.7428\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.6182 - accuracy: 0.7689\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.5786 - accuracy: 0.7939\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.5414 - accuracy: 0.8161\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.5075 - accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.4774 - accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.4495 - accuracy: 0.8617\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.4234 - accuracy: 0.8739\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.4003 - accuracy: 0.8817\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.3784 - accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.3585 - accuracy: 0.8961\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.3401 - accuracy: 0.9022\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.3218 - accuracy: 0.9117\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.3085 - accuracy: 0.9133\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.2914 - accuracy: 0.9156\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.2784 - accuracy: 0.9200\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.2655 - accuracy: 0.9283\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.2540 - accuracy: 0.9344\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.2443 - accuracy: 0.9356\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.2341 - accuracy: 0.9339\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.2240 - accuracy: 0.9417\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.2160 - accuracy: 0.9422\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.2076 - accuracy: 0.9433\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 35us/step - loss: 0.2014 - accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 36us/step - loss: 0.1931 - accuracy: 0.9483\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.1873 - accuracy: 0.9483\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.1805 - accuracy: 0.9494\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.1760 - accuracy: 0.9517\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.1694 - accuracy: 0.9550\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.1641 - accuracy: 0.9533\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.1615 - accuracy: 0.9528\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.1544 - accuracy: 0.9517\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.1507 - accuracy: 0.9561\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.1469 - accuracy: 0.9572\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1426 - accuracy: 0.9600\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.1428 - accuracy: 0.9544\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.1372 - accuracy: 0.9578\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.1323 - accuracy: 0.9611\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.1296 - accuracy: 0.9633\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.1260 - accuracy: 0.9622\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.1228 - accuracy: 0.9622\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1205 - accuracy: 0.9633\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.1174 - accuracy: 0.9672\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.1151 - accuracy: 0.9628\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1130 - accuracy: 0.9672\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.1116 - accuracy: 0.9656\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1107 - accuracy: 0.9678\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.1081 - accuracy: 0.9661\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.1098 - accuracy: 0.9706\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1030 - accuracy: 0.9706\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1015 - accuracy: 0.9722\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0978 - accuracy: 0.9739\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0967 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0947 - accuracy: 0.9722\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0924 - accuracy: 0.9761\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0910 - accuracy: 0.9744\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0897 - accuracy: 0.9756\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0885 - accuracy: 0.9739\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0871 - accuracy: 0.9756\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0850 - accuracy: 0.9756\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0850 - accuracy: 0.9744\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0834 - accuracy: 0.9772\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0820 - accuracy: 0.9761\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0801 - accuracy: 0.9778\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0778 - accuracy: 0.9789\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0768 - accuracy: 0.9794\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 0.0766 - accuracy: 0.9806\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0762 - accuracy: 0.9794\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0753 - accuracy: 0.9783\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0745 - accuracy: 0.9794\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0723 - accuracy: 0.9828\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0708 - accuracy: 0.9844\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0690 - accuracy: 0.9839\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0679 - accuracy: 0.9850\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0676 - accuracy: 0.9828\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0666 - accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0654 - accuracy: 0.9850\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0639 - accuracy: 0.9844\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0628 - accuracy: 0.9856\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0681 - accuracy: 0.9817\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0628 - accuracy: 0.9844\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0629 - accuracy: 0.9850\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0592 - accuracy: 0.9883\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0586 - accuracy: 0.9883\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0581 - accuracy: 0.9883\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0572 - accuracy: 0.9878\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0561 - accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 90.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 0s 134us/step - loss: 0.0551 - accuracy: 0.9906 - val_loss: 0.2268 - val_accuracy: 0.9050\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0552 - accuracy: 0.9889 - val_loss: 0.2367 - val_accuracy: 0.8950\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0553 - accuracy: 0.9867 - val_loss: 0.2272 - val_accuracy: 0.8950\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 41us/step - loss: 0.0543 - accuracy: 0.9917 - val_loss: 0.2406 - val_accuracy: 0.8800\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0525 - accuracy: 0.9900 - val_loss: 0.2327 - val_accuracy: 0.8950\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0533 - accuracy: 0.9883 - val_loss: 0.2236 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0511 - accuracy: 0.9911 - val_loss: 0.2276 - val_accuracy: 0.8950\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0499 - accuracy: 0.9911 - val_loss: 0.2318 - val_accuracy: 0.8950\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0493 - accuracy: 0.9928 - val_loss: 0.2304 - val_accuracy: 0.8850\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0501 - accuracy: 0.9889 - val_loss: 0.2332 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0484 - accuracy: 0.9922 - val_loss: 0.2343 - val_accuracy: 0.8950\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0479 - accuracy: 0.9911 - val_loss: 0.2266 - val_accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0467 - accuracy: 0.9928 - val_loss: 0.2238 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0470 - accuracy: 0.9933 - val_loss: 0.2386 - val_accuracy: 0.8850\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0454 - accuracy: 0.9911 - val_loss: 0.2366 - val_accuracy: 0.8800\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 0.2327 - val_accuracy: 0.8900\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0453 - accuracy: 0.9911 - val_loss: 0.2393 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0439 - accuracy: 0.9933 - val_loss: 0.2323 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0439 - accuracy: 0.9922 - val_loss: 0.2455 - val_accuracy: 0.8850\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0424 - accuracy: 0.9944 - val_loss: 0.2308 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.0434 - accuracy: 0.9922 - val_loss: 0.2375 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0410 - accuracy: 0.9933 - val_loss: 0.2354 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0404 - accuracy: 0.9956 - val_loss: 0.2327 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.0396 - accuracy: 0.9944 - val_loss: 0.2353 - val_accuracy: 0.8900\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0391 - accuracy: 0.9944 - val_loss: 0.2352 - val_accuracy: 0.8850\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 99us/step - loss: 0.0422 - accuracy: 0.9922 - val_loss: 0.2430 - val_accuracy: 0.8900\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.0384 - accuracy: 0.9944 - val_loss: 0.2377 - val_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0381 - accuracy: 0.9950 - val_loss: 0.2400 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0375 - accuracy: 0.9950 - val_loss: 0.2438 - val_accuracy: 0.8800\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0367 - accuracy: 0.9967 - val_loss: 0.2405 - val_accuracy: 0.8850\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0360 - accuracy: 0.9944 - val_loss: 0.2486 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0361 - accuracy: 0.9967 - val_loss: 0.2397 - val_accuracy: 0.8800\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0345 - accuracy: 0.9972 - val_loss: 0.2489 - val_accuracy: 0.8900\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0346 - accuracy: 0.9956 - val_loss: 0.2476 - val_accuracy: 0.8950\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0364 - accuracy: 0.9956 - val_loss: 0.2431 - val_accuracy: 0.8900\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0349 - accuracy: 0.9956 - val_loss: 0.2408 - val_accuracy: 0.8950\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0332 - accuracy: 0.9956 - val_loss: 0.2442 - val_accuracy: 0.8850\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0327 - accuracy: 0.9967 - val_loss: 0.2472 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0325 - accuracy: 0.9972 - val_loss: 0.2516 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0315 - accuracy: 0.9972 - val_loss: 0.2519 - val_accuracy: 0.8900\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 31us/step - loss: 0.0314 - accuracy: 0.9972 - val_loss: 0.2528 - val_accuracy: 0.8950\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0305 - accuracy: 0.9967 - val_loss: 0.2535 - val_accuracy: 0.8850\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0319 - accuracy: 0.9956 - val_loss: 0.2512 - val_accuracy: 0.8950\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0305 - accuracy: 0.9961 - val_loss: 0.2554 - val_accuracy: 0.8900\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0296 - accuracy: 0.9978 - val_loss: 0.2479 - val_accuracy: 0.8850\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0292 - accuracy: 0.9972 - val_loss: 0.2523 - val_accuracy: 0.8850\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0285 - accuracy: 0.9978 - val_loss: 0.2616 - val_accuracy: 0.8900\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0284 - accuracy: 0.9967 - val_loss: 0.2569 - val_accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0276 - accuracy: 0.9989 - val_loss: 0.2575 - val_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0274 - accuracy: 0.9983 - val_loss: 0.2554 - val_accuracy: 0.8850\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0271 - accuracy: 0.9983 - val_loss: 0.2608 - val_accuracy: 0.8900\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0287 - accuracy: 0.9978 - val_loss: 0.2688 - val_accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0271 - accuracy: 0.9983 - val_loss: 0.2642 - val_accuracy: 0.8950\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0278 - accuracy: 0.9983 - val_loss: 0.2636 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0259 - accuracy: 0.9983 - val_loss: 0.2620 - val_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.0251 - accuracy: 0.9983 - val_loss: 0.2697 - val_accuracy: 0.8950\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0247 - accuracy: 0.9989 - val_loss: 0.2683 - val_accuracy: 0.9050\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0242 - accuracy: 0.9989 - val_loss: 0.2831 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0238 - accuracy: 0.9989 - val_loss: 0.2673 - val_accuracy: 0.8900\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0234 - accuracy: 0.9989 - val_loss: 0.2747 - val_accuracy: 0.8950\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0231 - accuracy: 0.9989 - val_loss: 0.2727 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 35us/step - loss: 0.0231 - accuracy: 0.9978 - val_loss: 0.2746 - val_accuracy: 0.9050\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0234 - accuracy: 0.9978 - val_loss: 0.2791 - val_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0224 - accuracy: 0.9983 - val_loss: 0.2756 - val_accuracy: 0.8950\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0219 - accuracy: 0.9989 - val_loss: 0.2827 - val_accuracy: 0.8950\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0215 - accuracy: 0.9994 - val_loss: 0.2762 - val_accuracy: 0.8950\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0212 - accuracy: 0.9983 - val_loss: 0.2762 - val_accuracy: 0.8850\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0212 - accuracy: 0.9989 - val_loss: 0.2803 - val_accuracy: 0.8950\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 0.2846 - val_accuracy: 0.8950\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0222 - accuracy: 0.9989 - val_loss: 0.2824 - val_accuracy: 0.8900\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0206 - accuracy: 0.9994 - val_loss: 0.2838 - val_accuracy: 0.8900\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0198 - accuracy: 0.9989 - val_loss: 0.2876 - val_accuracy: 0.8900\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0198 - accuracy: 0.9994 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0196 - accuracy: 0.9989 - val_loss: 0.2948 - val_accuracy: 0.8900\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0194 - accuracy: 0.9989 - val_loss: 0.2988 - val_accuracy: 0.8900\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0191 - accuracy: 0.9994 - val_loss: 0.2934 - val_accuracy: 0.9050\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.8900\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.8950\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0179 - accuracy: 0.9989 - val_loss: 0.2927 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0171 - accuracy: 0.9994 - val_loss: 0.2979 - val_accuracy: 0.8900\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 42us/step - loss: 0.0170 - accuracy: 0.9994 - val_loss: 0.2945 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0157 - accuracy: 0.9994 - val_loss: 0.3091 - val_accuracy: 0.8900\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0157 - accuracy: 0.9994 - val_loss: 0.3040 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0153 - accuracy: 0.9994 - val_loss: 0.3120 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.3123 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.3231 - val_accuracy: 0.9050\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 107us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.8900\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
